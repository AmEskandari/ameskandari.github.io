---
layout: archive
title: "Jason's Notes"
permalink: /notes/
author_profile: true
---

Deep Learning
1. [Logistic regression](/files/lr.pdf)
2. [Backprop for logistic regression](/files/IMG_3902.JPG)
3. [Backprop for a two-layer neural net](/files/IMG_3903.JPG)
4. [Deriving backprop](/files/deriving_backprop.pdf)
5. [A pure numpy neural net in less than 200 lines (code)](https://github.com/jasonwei20/jasonwei20.github.io/blob/master/code/numpy_neural_net.py)
5. [Regularization, activation functions, initialization, optimization, batch norm](/files/improving_dnns.pdf)
6. [Convolutional neural nets](/files/cnns.pdf)
7. [Recurrent neural nets](/files/rnns.pdf)

Machine Learning
1. [Decision trees and random forests](/files/IMG_3905.JPG)
2. [Support vector machines and kernels](/files/IMG_3904.JPG)
3. [K-means](/files/k-means.pdf)

NLP
1. [Word embeddings](/files/word_embeddings.pdf)
2. [Attention](/files/attention.pdf)
3. [Transformers](/files/transformers.pdf)
4. [BERT](/files/bert.pdf)

To do
1. XLNet
2. BART
3. SimCLR

Computer Science
* [Algorithms](/files/algo_notes.pdf)

Most of my ML/DL notes are from Andrew Ng's *Deep Learning* and *Machine Learning* Coursera courses. I also really liked *Hands-On Machine Learning with Scikit-Learn and Tensorflow* by Aurélien Géron.

My NLP notes are based on content from Andrew Ng, Graham Neubig, papers, and YouTube explanations.
